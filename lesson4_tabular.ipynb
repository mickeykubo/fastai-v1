{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson4-tabular.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mickeykubo/fastai-v1/blob/master/lesson4_tabular.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "GDBkwz2Y69tc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tabular models"
      ]
    },
    {
      "metadata": {
        "id": "ny5LmDh16-8f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1621
        },
        "outputId": "d60d14ae-e89f-4ffc-fc8e-be06f1d36584"
      },
      "cell_type": "code",
      "source": [
        "!curl https://course-v3.fast.ai/setup/colab | bash"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   665  100   665    0     0   5884      0 --:--:-- --:--:-- --:--:--  5884\n",
            "Collecting pillow==4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e5/88b3d60924a3f8476fa74ec086f5fbaba56dd6cee0d82845f883b6b6dd18/Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.7MB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow==4.1.1) (0.46)\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-4.1.1\n",
            "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
            "Collecting torch_nightly\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/cu92/torch_nightly-1.0.0.dev20181206-cp36-cp36m-linux_x86_64.whl (576.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 576.2MB 22kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x6289e000 @  0x7ff1717e12a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch-nightly\n",
            "Successfully installed torch-nightly-1.0.0.dev20181206\n",
            "Cloning into 'course-v3'...\n",
            "remote: Enumerating objects: 2809, done.\u001b[K\n",
            "remote: Total 2809 (delta 0), reused 0 (delta 0), pack-reused 2809\u001b[K\n",
            "Receiving objects: 100% (2809/2809), 105.10 MiB | 29.03 MiB/s, done.\n",
            "Resolving deltas: 100% (1539/1539), done.\n",
            "Collecting fastai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/17/b5ab3f9a44b45661d9eb6e29001fe39c39ebb287ce9a9f1670d07bda0d4d/fastai-1.0.39-py3-none-any.whl (150kB)\n",
            "\u001b[K    100% |████████████████████████████████| 153kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (2.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.22.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.18.4)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (18.0)\n",
            "Requirement already satisfied, skipping upgrade: spacy>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.0.18)\n",
            "Collecting nvidia-ml-py3 (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/6d/64/cce82bddb80c0b0f5c703bbdafa94bfb69a1c5ad7a79cff00b482468f0d3/nvidia-ml-py3-7.352.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.0)\n",
            "Collecting torchvision (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 21.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.6.9)\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (4.1.1)\n",
            "Collecting fastprogress>=0.1.18 (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/78/57/24a5e20f4a357f7f1c90dd5250071951c832b2480fd4fefd7be48edf4180/fastprogress-0.1.18-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Collecting torch (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 591.8MB 18kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x6144c000 @  0x7f6cfee3b2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hCollecting dataclasses; python_version < \"3.7\" (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.14.6)\n",
            "Collecting typing (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/bd/eee1157fc2d8514970b345d69cb9975dcd1e42cd7e61146ed841f6e68309/typing-3.6.6-py3-none-any.whl\n",
            "Collecting bottleneck (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/ae/cedf5323f398ab4e4ff92d6c431a3e1c6a186f9b41ab3e8258dff786a290/Bottleneck-1.2.1.tar.gz (105kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 35.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2018.7)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2018.11.29)\n",
            "Requirement already satisfied, skipping upgrade: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (6.12.1)\n",
            "Requirement already satisfied, skipping upgrade: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.35)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.2.8.2)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2018.1.10)\n",
            "Requirement already satisfied, skipping upgrade: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai) (0.46)\n",
            "Requirement already satisfied, skipping upgrade: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (1.10.11)\n",
            "Requirement already satisfied, skipping upgrade: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.5.6)\n",
            "Requirement already satisfied, skipping upgrade: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.9.0.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.9.0)\n",
            "Building wheels for collected packages: nvidia-ml-py3, bottleneck\n",
            "  Running setup.py bdist_wheel for nvidia-ml-py3 ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e4/1d/06/640c93f5270d67d0247f30be91f232700d19023f9e66d735c7\n",
            "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f2/bf/ec/e0f39aa27001525ad455139ee57ec7d0776fe074dfd78c97e4\n",
            "Successfully built nvidia-ml-py3 bottleneck\n",
            "Installing collected packages: nvidia-ml-py3, torch, torchvision, fastprogress, dataclasses, typing, bottleneck, fastai\n",
            "Successfully installed bottleneck-1.2.1 dataclasses-0.6 fastai-1.0.39 fastprogress-0.1.18 nvidia-ml-py3-7.352.0 torch-1.0.0 torchvision-0.2.1 typing-3.6.6\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OeeB7tYR69tg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai.tabular import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BsNrRbSS69tr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tabular data should be in a Pandas `DataFrame`."
      ]
    },
    {
      "metadata": {
        "id": "jNYmRBzy69tt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.ADULT_SAMPLE)\n",
        "df = pd.read_csv(path/'adult.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dyRWlzfN69t2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dep_var = 'salary'\n",
        "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
        "cont_names = ['age', 'fnlwgt', 'education-num']\n",
        "procs = [FillMissing, Categorify, Normalize]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gUAEvkzK69t9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test = TabularList.from_df(df.iloc[800:1000].copy(), path=path, cat_names=cat_names, cont_names=cont_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T5ylr23m69uF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = (TabularList.from_df(df, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
        "                           .split_by_idx(list(range(800,1000)))\n",
        "                           .label_from_df(cols=dep_var)\n",
        "                           .add_test(test)\n",
        "                           .databunch())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iLqo7G5W69uL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "13561fc5-5e3f-4f2a-e5a2-5c6e214d09a5"
      },
      "cell_type": "code",
      "source": [
        "data.show_batch(rows=10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <col width='10%'>  <tr>\n",
              "    <th>workclass</th>\n",
              "    <th>education</th>\n",
              "    <th>marital-status</th>\n",
              "    <th>occupation</th>\n",
              "    <th>relationship</th>\n",
              "    <th>race</th>\n",
              "    <th>education-num_na</th>\n",
              "    <th>age</th>\n",
              "    <th>fnlwgt</th>\n",
              "    <th>education-num</th>\n",
              "    <th>target</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th> Private</th>\n",
              "    <th> 7th-8th</th>\n",
              "    <th> Never-married</th>\n",
              "    <th> Other-service</th>\n",
              "    <th> Own-child</th>\n",
              "    <th> White</th>\n",
              "    <th>False</th>\n",
              "    <th>0.0303</th>\n",
              "    <th>0.0433</th>\n",
              "    <th>-2.3781</th>\n",
              "    <th><50k</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th> Private</th>\n",
              "    <th> 12th</th>\n",
              "    <th> Married-civ-spouse</th>\n",
              "    <th> Adm-clerical</th>\n",
              "    <th> Husband</th>\n",
              "    <th> White</th>\n",
              "    <th>False</th>\n",
              "    <th>0.4701</th>\n",
              "    <th>1.6038</th>\n",
              "    <th>-0.8135</th>\n",
              "    <th><50k</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th> Private</th>\n",
              "    <th> HS-grad</th>\n",
              "    <th> Never-married</th>\n",
              "    <th> Other-service</th>\n",
              "    <th> Other-relative</th>\n",
              "    <th> Asian-Pac-Islander</th>\n",
              "    <th>False</th>\n",
              "    <th>-0.9959</th>\n",
              "    <th>-0.3771</th>\n",
              "    <th>-0.4224</th>\n",
              "    <th><50k</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th> Private</th>\n",
              "    <th> Bachelors</th>\n",
              "    <th> Married-civ-spouse</th>\n",
              "    <th> Prof-specialty</th>\n",
              "    <th> Wife</th>\n",
              "    <th> White</th>\n",
              "    <th>False</th>\n",
              "    <th>-0.5561</th>\n",
              "    <th>-1.3820</th>\n",
              "    <th>1.1422</th>\n",
              "    <th><50k</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th> Self-emp-not-inc</th>\n",
              "    <th> Bachelors</th>\n",
              "    <th> Married-civ-spouse</th>\n",
              "    <th> Exec-managerial</th>\n",
              "    <th> Husband</th>\n",
              "    <th> White</th>\n",
              "    <th>False</th>\n",
              "    <th>-0.1896</th>\n",
              "    <th>0.1254</th>\n",
              "    <th>1.1422</th>\n",
              "    <th><50k</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th> Private</th>\n",
              "    <th> Some-college</th>\n",
              "    <th> Separated</th>\n",
              "    <th> Exec-managerial</th>\n",
              "    <th> Unmarried</th>\n",
              "    <th> White</th>\n",
              "    <th>False</th>\n",
              "    <th>0.1036</th>\n",
              "    <th>0.0559</th>\n",
              "    <th>-0.0312</th>\n",
              "    <th><50k</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th> Private</th>\n",
              "    <th> Assoc-voc</th>\n",
              "    <th> Never-married</th>\n",
              "    <th> Exec-managerial</th>\n",
              "    <th> Own-child</th>\n",
              "    <th> White</th>\n",
              "    <th>False</th>\n",
              "    <th>0.5434</th>\n",
              "    <th>0.0141</th>\n",
              "    <th>0.3599</th>\n",
              "    <th><50k</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th> Private</th>\n",
              "    <th> HS-grad</th>\n",
              "    <th> Married-civ-spouse</th>\n",
              "    <th> Transport-moving</th>\n",
              "    <th> Husband</th>\n",
              "    <th> White</th>\n",
              "    <th>False</th>\n",
              "    <th>-0.7027</th>\n",
              "    <th>-0.3635</th>\n",
              "    <th>-0.4224</th>\n",
              "    <th><50k</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th> Private</th>\n",
              "    <th> HS-grad</th>\n",
              "    <th> Never-married</th>\n",
              "    <th> Adm-clerical</th>\n",
              "    <th> Not-in-family</th>\n",
              "    <th> White</th>\n",
              "    <th>False</th>\n",
              "    <th>0.3235</th>\n",
              "    <th>-1.0738</th>\n",
              "    <th>-0.4224</th>\n",
              "    <th><50k</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th> Self-emp-not-inc</th>\n",
              "    <th> HS-grad</th>\n",
              "    <th> Married-civ-spouse</th>\n",
              "    <th> Sales</th>\n",
              "    <th> Husband</th>\n",
              "    <th> White</th>\n",
              "    <th>False</th>\n",
              "    <th>-0.6294</th>\n",
              "    <th>0.5114</th>\n",
              "    <th>-0.4224</th>\n",
              "    <th><50k</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_i9cWXQm69uV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = tabular_learner(data, layers=[200,100], metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j8SLOixd69ua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "bc215095-a678-4416-c2e1-054e1b852cc0"
      },
      "cell_type": "code",
      "source": [
        "learn.fit(1, 1e-2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:06 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>0.368374</th>\n",
              "    <th>0.378342</th>\n",
              "    <th>0.820000</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "zHHDT9D069ul",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ]
    },
    {
      "metadata": {
        "id": "V0UddJPS69um",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "row = df.iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XcJOFWhM69uq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e017ca01-e7e8-41a3-9dbc-afff3aaceb23"
      },
      "cell_type": "code",
      "source": [
        "learn.predict(row)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category >=50k, tensor(1), tensor([0.3054, 0.6946]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "HAfEIZeJ69uv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}