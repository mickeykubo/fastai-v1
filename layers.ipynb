{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "layers.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "QDqP5_OG0vNa",
        "VD_8kYkD0vN1",
        "YnA2kwaW0vOR",
        "pM_tNB210vOc",
        "Y0esLd6H0vPD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mickeykubo/fastai-v1/blob/master/layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "V0Aq4_8Y0vL4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Layers"
      ]
    },
    {
      "metadata": {
        "id": "aVVzTAPR0wmm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "dfe6c173-eb9f-4272-d4ab-3356eb325357"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install https://download.pytorch.org/whl/cu80/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "!pip3 install fastai\n",
        "!pip3 install Pillow==4.1.1\n",
        "# fast.ai が準備した以下のコマンドだと1行でいける．\n",
        "# 注意：Google Colabの環境が変わる可能性がある．\n",
        "#curl https://course-v3.fast.ai/setup/colab | bash"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.0.0 from https://download.pytorch.org/whl/cu80/torch-1.0.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (1.0.42)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai) (1.2.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.6.9)\n",
            "Requirement already satisfied: fastprogress>=0.1.18 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.1.18)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (4.1.1)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.0.18)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.18.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (0.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.2.1)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.352.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (19.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.0)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from fastai) (3.6.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai) (4.6.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.22.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai) (0.46)\n",
            "Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2018.1.10)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.2.9)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (6.12.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.9.6)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.35)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.2)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2018.11.29)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.22)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->fastai) (1.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (2.3.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.4.3.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (4.28.1)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.9.0.1)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (1.10.11)\n",
            "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.5.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->fastai) (40.8.0)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.9.0)\n",
            "Requirement already satisfied: Pillow==4.1.1 in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.1.1) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i4g-dQgs0vL5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This module contains many layer classes that we might be interested in using in our models. These layers complement the default [Pytorch layers](https://pytorch.org/docs/stable/nn.html) which we can also use as predefined layers."
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "ftMGc7fE0vL6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai.vision import *\n",
        "from fastai.gen_doc.nbdoc import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AOptLl040vL9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Custom fastai modules"
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "Mo-gXCD70vL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2d1814f-4e9b-47aa-d1df-8c1e06e020c7"
      },
      "cell_type": "code",
      "source": [
        "show_doc(AdaptiveConcatPool2d, title_level=3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h3 id=\"AdaptiveConcatPool2d\"><code>class</code> <code>AdaptiveConcatPool2d</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L171\" class=\"source_link\">[source]</a></h3>\n\n> <code>AdaptiveConcatPool2d</code>(<b>`sz`</b>:`Optional`\\[`int`\\]=<b><i>`None`</i></b>) :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n\nLayer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "IblLLWJR0vMD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai.gen_doc.nbdoc import *\n",
        "from fastai.layers import * "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9OqbVfH00vMG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The output will be `2*sz`, or just 2 if `sz` is None."
      ]
    },
    {
      "metadata": {
        "id": "xtZzIxmj0vMG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The [`AdaptiveConcatPool2d`](/layers.html#AdaptiveConcatPool2d) object uses adaptive average pooling and adaptive max pooling and concatenates them both. We use this because it provides the model with the information of both methods and improves performance. This technique is called `adaptive` because it allows us to decide on what output dimensions we want, instead of choosing the input's dimensions to fit a desired output size.\n",
        "\n",
        "Let's try training with Adaptive Average Pooling first, then with Adaptive Max Pooling and finally with the concatenation of them both to see how they fare in performance.\n",
        "\n",
        "We will first define a [`simple_cnn`](/layers.html#simple_cnn) using [Adaptive Max Pooling](https://pytorch.org/docs/stable/nn.html#torch.nn.AdaptiveMaxPool2d) by changing the source code a bit."
      ]
    },
    {
      "metadata": {
        "id": "CeHQzdiW0vMH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "data = ImageDataBunch.from_folder(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YG3cyCBG0vMK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def simple_cnn_max(actns:Collection[int], kernel_szs:Collection[int]=None,\n",
        "               strides:Collection[int]=None) -> nn.Sequential:\n",
        "    \"CNN with `conv2d_relu` layers defined by `actns`, `kernel_szs` and `strides`\"\n",
        "    nl = len(actns)-1\n",
        "    kernel_szs = ifnone(kernel_szs, [3]*nl)\n",
        "    strides    = ifnone(strides   , [2]*nl)\n",
        "    layers = [conv_layer(actns[i], actns[i+1], kernel_szs[i], stride=strides[i])\n",
        "        for i in range(len(strides))]\n",
        "    layers.append(nn.Sequential(nn.AdaptiveMaxPool2d(1), Flatten()))\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aXK9nc500vMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "05cfb67d-1bbc-4c3b-dffa-8b30ea9df802"
      },
      "cell_type": "code",
      "source": [
        "model = simple_cnn_max((3,16,16,2))\n",
        "learner = Learner(data, model, metrics=[accuracy])\n",
        "learner.fit(1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:12 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>0.106114</th>\n",
              "    <th>0.076576</th>\n",
              "    <th>0.980373</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9hf5WxTt0vMP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's try with [Adaptive Average Pooling](https://pytorch.org/docs/stable/nn.html#torch.nn.AdaptiveAvgPool2d) now."
      ]
    },
    {
      "metadata": {
        "id": "8j4DumG_0vMR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def simple_cnn_avg(actns:Collection[int], kernel_szs:Collection[int]=None,\n",
        "               strides:Collection[int]=None) -> nn.Sequential:\n",
        "    \"CNN with `conv2d_relu` layers defined by `actns`, `kernel_szs` and `strides`\"\n",
        "    nl = len(actns)-1\n",
        "    kernel_szs = ifnone(kernel_szs, [3]*nl)\n",
        "    strides    = ifnone(strides   , [2]*nl)\n",
        "    layers = [conv_layer(actns[i], actns[i+1], kernel_szs[i], stride=strides[i])\n",
        "        for i in range(len(strides))]\n",
        "    layers.append(nn.Sequential(nn.AdaptiveAvgPool2d(1), Flatten()))\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gVYULUz80vMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "ff80525a-c02c-4d27-8d15-af201063e78d"
      },
      "cell_type": "code",
      "source": [
        "model = simple_cnn_avg((3,16,16,2))\n",
        "learner = Learner(data, model, metrics=[accuracy])\n",
        "learner.fit(1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:11 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>0.266963</th>\n",
              "    <th>0.213397</th>\n",
              "    <th>0.977920</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "hPF87aAE0vMW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally we will try with the concatenation of them both [`AdaptiveConcatPool2d`](/layers.html#AdaptiveConcatPool2d). We will see that, in fact, it increases our accuracy and decreases our loss considerably!"
      ]
    },
    {
      "metadata": {
        "id": "RDF1KyfT0vMX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def simple_cnn(actns:Collection[int], kernel_szs:Collection[int]=None,\n",
        "               strides:Collection[int]=None) -> nn.Sequential:\n",
        "    \"CNN with `conv2d_relu` layers defined by `actns`, `kernel_szs` and `strides`\"\n",
        "    nl = len(actns)-1\n",
        "    kernel_szs = ifnone(kernel_szs, [3]*nl)\n",
        "    strides    = ifnone(strides   , [2]*nl)\n",
        "    layers = [conv_layer(actns[i], actns[i+1], kernel_szs[i], stride=strides[i])\n",
        "        for i in range(len(strides))]\n",
        "    layers.append(nn.Sequential(AdaptiveConcatPool2d(1), Flatten()))\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W_uZfKwh0vMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "1ef8b289-4647-4be0-d5fd-ded2f4286d3d"
      },
      "cell_type": "code",
      "source": [
        "model = simple_cnn((3,16,16,2))\n",
        "learner = Learner(data, model, metrics=[accuracy])\n",
        "learner.fit(1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:11 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>0.139438</th>\n",
              "    <th>0.113247</th>\n",
              "    <th>0.978901</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "K7OpuTDa0vMd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7fed9d83-89d1-4191-e809-dae2a87c72d0"
      },
      "cell_type": "code",
      "source": [
        "show_doc(Lambda, title_level=3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h3 id=\"Lambda\"><code>class</code> <code>Lambda</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L10\" class=\"source_link\">[source]</a></h3>\n\n> <code>Lambda</code>(<b>`func`</b>:`LambdaFunc`) :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n\nAn easy way to create a pytorch layer for a simple `func`.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ED4ouKxR0vMg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is very useful to use functions as layers in our networks inside a [Sequential](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential) object. So, for example, say we want to apply a [log_softmax loss](https://pytorch.org/docs/stable/nn.html#torch.nn.functional.log_softmax) and we need to change the shape of our output batches to be able to use this loss. We can add a layer that applies the necessary change in shape by calling:\n",
        "\n",
        "`Lambda(lambda x: x.view(x.size(0),-1))`"
      ]
    },
    {
      "metadata": {
        "id": "aBd3FTVL0vMi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's see an example of how the shape of our output can change when we add this layer."
      ]
    },
    {
      "metadata": {
        "id": "q7nMuytQ0vMi",
        "colab_type": "code",
        "colab": {},
        "outputId": "91036cd2-8ce7-45e3-c612-fc0cdbfa17e1"
      },
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3,  16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "    nn.AdaptiveAvgPool2d(1),\n",
        ")\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "for xb, yb in data.train_dl:\n",
        "    out = (model(*[xb]))\n",
        "    print(out.size())\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X8k7NSM60vMm",
        "colab_type": "code",
        "colab": {},
        "outputId": "bd8045f7-3a8f-4149-fa76-ecd2819f0619"
      },
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3,  16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "    nn.AdaptiveAvgPool2d(1),\n",
        "    Lambda(lambda x: x.view(x.size(0),-1))\n",
        ")\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "for xb, yb in data.train_dl:\n",
        "    out = (model(*[xb]))\n",
        "    print(out.size())\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "R1euydSL0vMq",
        "colab_type": "code",
        "colab": {},
        "outputId": "081ac3b5-220b-4e05-8050-cc3590953f51"
      },
      "cell_type": "code",
      "source": [
        "show_doc(Flatten)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h2 id=\"Flatten\"><code>class</code> <code>Flatten</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L23\" class=\"source_link\">[source]</a></h2>\n\n> <code>Flatten</code>(**`full`**:`bool`=***`False`***) :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n\nFlatten `x` to a single dimension, often used at the end of a model. `full` for rank-1 tensor  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "KyWgBj_G0vMu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The function we build above is actually implemented in our library as [`Flatten`](/layers.html#Flatten). We can see that it returns the same size when we run it."
      ]
    },
    {
      "metadata": {
        "id": "fbLoV0F-0vMw",
        "colab_type": "code",
        "colab": {},
        "outputId": "a2797f66-d512-4d28-b88c-a41948db30de"
      },
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3,  16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "    nn.AdaptiveAvgPool2d(1),\n",
        "    Flatten(),\n",
        ")\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "for xb, yb in data.train_dl:\n",
        "    out = (model(*[xb]))\n",
        "    print(out.size())\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "rLJh2rJS0vMz",
        "colab_type": "code",
        "colab": {},
        "outputId": "15f43d0e-263b-4357-c2c7-4404c7526574"
      },
      "cell_type": "code",
      "source": [
        "show_doc(PoolFlatten)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"PoolFlatten\"><code>PoolFlatten</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L34\" class=\"source_link\">[source]</a></h4>\n\n> <code>PoolFlatten</code>() → [`Sequential`](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential)\n\nApply [`nn.AdaptiveAvgPool2d`](https://pytorch.org/docs/stable/nn.html#torch.nn.AdaptiveAvgPool2d) to `x` and then flatten the result.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "G1Xg67P_0vM2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can combine these two final layers ([AdaptiveAvgPool2d](https://pytorch.org/docs/stable/nn.html#torch.nn.AdaptiveAvgPool2d) and [`Flatten`](/layers.html#Flatten)) by using [`PoolFlatten`](/layers.html#PoolFlatten)."
      ]
    },
    {
      "metadata": {
        "id": "9HgK5jAZ0vM3",
        "colab_type": "code",
        "colab": {},
        "outputId": "5c6a8854-4417-40e3-fb40-2bb88061c1b9"
      },
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3,  16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "    PoolFlatten()\n",
        ")\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "for xb, yb in data.train_dl:\n",
        "    out = (model(*[xb]))\n",
        "    print(out.size())\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2CRKR3lt0vM5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Another use we give to the Lambda function is to resize batches with [`ResizeBatch`](/layers.html#ResizeBatch) when we have a layer that expects a different input than what comes from the previous one."
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "T1TZXs1d0vM7",
        "colab_type": "code",
        "colab": {},
        "outputId": "d161f91d-d230-4eec-a0ec-de35b2794aff"
      },
      "cell_type": "code",
      "source": [
        "show_doc(ResizeBatch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"ResizeBatch\"><code>ResizeBatch</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L19\" class=\"source_link\">[source]</a></h4>\n\n> <code>ResizeBatch</code>(**\\*`size`**:`int`) → `Tensor`\n\nLayer that resizes x to `size`, good for connecting mismatched layers.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gCswD8450vM_",
        "colab_type": "code",
        "colab": {},
        "outputId": "03836362-ee97-4032-e5ab-0fe84a08203e"
      },
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1., -1.], [1., -1.]])\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1., -1.],\n",
            "        [ 1., -1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o32NV7eF0vNB",
        "colab_type": "code",
        "colab": {},
        "outputId": "74714c78-62da-470b-c284-8ee9f69488d1"
      },
      "cell_type": "code",
      "source": [
        "out = ResizeBatch(4)\n",
        "print(out(a))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1., -1.,  1., -1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "SgbdYkvG0vNF",
        "colab_type": "code",
        "colab": {},
        "outputId": "a638ff11-6875-4a08-d474-e60e099a0dc7"
      },
      "cell_type": "code",
      "source": [
        "show_doc(Debugger, title_level=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h3 id=\"Debugger\"><code>class</code> <code>Debugger</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L180\" class=\"source_link\">[source]</a></h3>\n\n> <code>Debugger</code>() :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n\nA module to debug inside a model.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "AU1VDr730vNH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The debugger module allows us to peek inside a network while its training and see in detail what is going on. We can see inputs, outputs and sizes at any point in the network.\n",
        "\n",
        "For instance, if you run the following:\n",
        "\n",
        "``` python\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3,  16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "    Debugger(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        ")\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "learner = Learner(data, model, metrics=[accuracy])\n",
        "learner.fit(5)\n",
        "```\n",
        "... you'll see something like this:\n",
        "\n",
        "```\n",
        "/home/ubuntu/fastai/fastai/layers.py(74)forward()\n",
        "     72     def forward(self,x:Tensor) -> Tensor:\n",
        "     73         set_trace()\n",
        "---> 74         return x\n",
        "     75 \n",
        "     76 class StdUpsample(nn.Module):\n",
        "\n",
        "ipdb>\n",
        "```"
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "tQEqf4VR0vNH",
        "colab_type": "code",
        "colab": {},
        "outputId": "3bea8995-5c85-41c0-9e0a-dc9b86fb9e62"
      },
      "cell_type": "code",
      "source": [
        "show_doc(PixelShuffle_ICNR, title_level=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h3 id=\"PixelShuffle_ICNR\"><code>class</code> <code>PixelShuffle_ICNR</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L196\" class=\"source_link\">[source]</a></h3>\n\n> <code>PixelShuffle_ICNR</code>(**`ni`**:`int`, **`nf`**:`int`=***`None`***, **`scale`**:`int`=***`2`***, **`blur`**:`bool`=***`False`***, **`norm_type`**=***`<NormType.Weight: 3>`***, **`leaky`**:`float`=***`None`***) :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n\nUpsample by `scale` from `ni` filters to `nf` (default `ni`), using [`nn.PixelShuffle`](https://pytorch.org/docs/stable/nn.html#torch.nn.PixelShuffle), [`icnr`](/layers.html#icnr) init, and [`weight_norm`](https://pytorch.org/docs/stable/nn.html#torch.nn.weight_norm).  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "vcIDbenK0vNK",
        "colab_type": "code",
        "colab": {},
        "outputId": "4ef01635-5106-453b-b2cf-c3b738294aa8"
      },
      "cell_type": "code",
      "source": [
        "show_doc(MergeLayer, title_level=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h3 id=\"MergeLayer\"><code>class</code> <code>MergeLayer</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L132\" class=\"source_link\">[source]</a></h3>\n\n> <code>MergeLayer</code>(**`dense`**:`bool`=***`False`***) :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n\nMerge a shortcut with the result of the module by adding them or concatenating thme if `dense=True`.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "u6qb8pGM0vNM",
        "colab_type": "code",
        "colab": {},
        "outputId": "9486811f-4645-4880-a4f4-2629785871bd"
      },
      "cell_type": "code",
      "source": [
        "show_doc(PartialLayer, title_level=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h3 id=\"PartialLayer\"><code>class</code> <code>PartialLayer</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L161\" class=\"source_link\">[source]</a></h3>\n\n> <code>PartialLayer</code>(**`func`**, **\\*\\*`kwargs`**) :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n\nLayer that applies `partial(func, **kwargs)`.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "eVqwEO0s0vNP",
        "colab_type": "code",
        "colab": {},
        "outputId": "958d3222-d781-4262-c707-8ffb254b6d46"
      },
      "cell_type": "code",
      "source": [
        "show_doc(SigmoidRange, title_level=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h3 id=\"SigmoidRange\"><code>class</code> <code>SigmoidRange</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L153\" class=\"source_link\">[source]</a></h3>\n\n> <code>SigmoidRange</code>(**`low`**, **`high`**) :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n\nSigmoid module with range `(low,x_max)`  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "I99U5S6a0vNT",
        "colab_type": "code",
        "colab": {},
        "outputId": "a483ebad-11ce-4271-924c-b361e1651e04"
      },
      "cell_type": "code",
      "source": [
        "show_doc(SequentialEx, title_level=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h3 id=\"SequentialEx\"><code>class</code> <code>SequentialEx</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L111\" class=\"source_link\">[source]</a></h3>\n\n> <code>SequentialEx</code>(**\\*`layers`**) :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n\nLike [`nn.Sequential`](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential), but with ModuleList semantics, and can access module input  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "y-9W9hDe0vNV",
        "colab_type": "code",
        "colab": {},
        "outputId": "b30398ab-c55d-4d32-8326-d74c0d513f3c"
      },
      "cell_type": "code",
      "source": [
        "show_doc(SelfAttention, title_level=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h3 id=\"SelfAttention\"><code>class</code> <code>SelfAttention</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L63\" class=\"source_link\">[source]</a></h3>\n\n> <code>SelfAttention</code>(**`n_channels`**:`int`) :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n\nSelf attention layer for 2d.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "nmORO7fD0vNY",
        "colab_type": "code",
        "colab": {},
        "outputId": "9c94a013-cef0-47fe-9373-69ae1ca914a2"
      },
      "cell_type": "code",
      "source": [
        "show_doc(BatchNorm1dFlat, title_level=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h3 id=\"BatchNorm1dFlat\"><code>class</code> <code>BatchNorm1dFlat</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L280\" class=\"source_link\">[source]</a></h3>\n\n> <code>BatchNorm1dFlat</code>(**`num_features`**, **`eps`**=***`1e-05`***, **`momentum`**=***`0.1`***, **`affine`**=***`True`***, **`track_running_stats`**=***`True`***) :: [`BatchNorm1d`](https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm1d)\n\n[`nn.BatchNorm1d`](https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm1d), but first flattens leading dimensions  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "QDqP5_OG0vNa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loss functions"
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "nyZag5iv0vNa",
        "colab_type": "code",
        "colab": {},
        "outputId": "7fc79e78-cf6a-4e2e-d1cd-be57db204831"
      },
      "cell_type": "code",
      "source": [
        "show_doc(FlattenedLoss, title_level=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h3 id=\"FlattenedLoss\"><code>class</code> <code>FlattenedLoss</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L215\" class=\"source_link\">[source]</a></h3>\n\n> <code>FlattenedLoss</code>(**`func`**, **\\*`args`**, **`axis`**:`int`=***`-1`***, **`floatify`**:`bool`=***`False`***, **`is_2d`**:`bool`=***`True`***, **\\*\\*`kwargs`**)\n\nSame as `func`, but flattens input and target.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lr2GKdVp0vNd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create an instance of `func` with `args` and `kwargs`. When passing an output and target, it\n",
        "- puts `axis` first in output and target with a transpose\n",
        "- casts the target to `float` is `floatify=True`\n",
        "- squeezes the `output` to two dimensions if `is_2d`, otherwise one dimension, squeezes the target to one dimension\n",
        "- applied the instance of `func`."
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "Hvtlt1rc0vNe",
        "colab_type": "code",
        "colab": {},
        "outputId": "265b0797-0d2e-4a97-8e19-f3e449ddc587"
      },
      "cell_type": "code",
      "source": [
        "show_doc(BCEFlat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"BCEFlat\"><code>BCEFlat</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L241\" class=\"source_link\">[source]</a></h4>\n\n> <code>BCEFlat</code>(**\\*`args`**, **`axis`**:`int`=***`-1`***, **`floatify`**:`bool`=***`True`***, **\\*\\*`kwargs`**)\n\nSame as [`nn.BCELoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.BCELoss), but flattens input and target.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "vn8cFJ1X0vNg",
        "colab_type": "code",
        "colab": {},
        "outputId": "9f93687f-ccfc-4717-a8ca-2cc50c1146c6"
      },
      "cell_type": "code",
      "source": [
        "show_doc(BCEWithLogitsFlat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"BCEWithLogitsFlat\"><code>BCEWithLogitsFlat</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L237\" class=\"source_link\">[source]</a></h4>\n\n> <code>BCEWithLogitsFlat</code>(**\\*`args`**, **`axis`**:`int`=***`-1`***, **`floatify`**:`bool`=***`True`***, **\\*\\*`kwargs`**)\n\nSame as [`nn.BCEWithLogitsLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.BCEWithLogitsLoss), but flattens input and target.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "5RxSvX6m0vNo",
        "colab_type": "code",
        "colab": {},
        "outputId": "6e98c723-9935-4bcb-a99f-0cb9d3cf2d7c"
      },
      "cell_type": "code",
      "source": [
        "show_doc(CrossEntropyFlat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"CrossEntropyFlat\"><code>CrossEntropyFlat</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L233\" class=\"source_link\">[source]</a></h4>\n\n> <code>CrossEntropyFlat</code>(**\\*`args`**, **`axis`**:`int`=***`-1`***, **\\*\\*`kwargs`**)\n\nSame as [`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss), but flattens input and target.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "O9Mlw60o0vNr",
        "colab_type": "code",
        "colab": {},
        "outputId": "88e0e2f8-e3eb-4e34-bfc8-3cc77516a4c7"
      },
      "cell_type": "code",
      "source": [
        "show_doc(MSELossFlat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"MSELossFlat\"><code>MSELossFlat</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L245\" class=\"source_link\">[source]</a></h4>\n\n> <code>MSELossFlat</code>(**\\*`args`**, **`axis`**:`int`=***`-1`***, **`floatify`**:`bool`=***`True`***, **\\*\\*`kwargs`**)\n\nSame as [`nn.MSELoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.MSELoss), but flattens input and target.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "Nv5_RQki0vNv",
        "colab_type": "code",
        "colab": {},
        "outputId": "e1035ff5-8d47-45e7-adfc-8b81c27e9632"
      },
      "cell_type": "code",
      "source": [
        "show_doc(NoopLoss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h2 id=\"NoopLoss\"><code>class</code> <code>NoopLoss</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L249\" class=\"source_link\">[source]</a></h2>\n\n> <code>NoopLoss</code>() :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n\nJust returns the mean of the `output`.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "l1nFynkk0vNz",
        "colab_type": "code",
        "colab": {},
        "outputId": "c97b48e9-8a1a-48bb-886f-0473c9983cf6"
      },
      "cell_type": "code",
      "source": [
        "show_doc(WassersteinLoss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h2 id=\"WassersteinLoss\"><code>class</code> <code>WassersteinLoss</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L253\" class=\"source_link\">[source]</a></h2>\n\n> <code>WassersteinLoss</code>() :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n\nFor WGAN.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "VD_8kYkD0vN1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper functions to create modules"
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "zUc-DX1n0vN1",
        "colab_type": "code",
        "colab": {},
        "outputId": "50294b3d-9f8a-459a-bfcf-e2eaa68dc9ea"
      },
      "cell_type": "code",
      "source": [
        "show_doc(bn_drop_lin, doc_string=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"bn_drop_lin\"><code>bn_drop_lin</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L48\" class=\"source_link\">[source]</a></h4>\n\n> <code>bn_drop_lin</code>(**`n_in`**:`int`, **`n_out`**:`int`, **`bn`**:`bool`=***`True`***, **`p`**:`float`=***`0.0`***, **`actn`**:`Optional`\\[[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\\]=***`None`***)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TqWRNJbK0vN4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The [`bn_drop_lin`](/layers.html#bn_drop_lin) function returns a sequence of [batch normalization](https://arxiv.org/abs/1502.03167), [dropout](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf) and a linear layer. This custom layer is usually used at the end of a model. \n",
        "\n",
        "`n_in` represents the number of size of the input `n_out` the size of the output, `bn` whether we want batch norm or not, `p` is how much dropout and `actn` is an optional parameter to add an activation function at the end."
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "LrJZ907R0vN5",
        "colab_type": "code",
        "colab": {},
        "outputId": "61f5b964-6b0a-407b-e85a-9c1b9d6cca08"
      },
      "cell_type": "code",
      "source": [
        "show_doc(conv2d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"conv2d\"><code>conv2d</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L81\" class=\"source_link\">[source]</a></h4>\n\n> <code>conv2d</code>(**`ni`**:`int`, **`nf`**:`int`, **`ks`**:`int`=***`3`***, **`stride`**:`int`=***`1`***, **`padding`**:`int`=***`None`***, **`bias`**=***`False`***, **`init`**:`LayerFunc`=***`'kaiming_normal_'`***) → [`Conv2d`](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d)\n\nCreate and initialize [`nn.Conv2d`](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d) layer. `padding` defaults to `ks//2`.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "X6DrdR1g0vN-",
        "colab_type": "code",
        "colab": {},
        "outputId": "ce646748-1934-4018-a95c-7d43f1f361b2"
      },
      "cell_type": "code",
      "source": [
        "show_doc(conv2d_trans)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"conv2d_trans\"><code>conv2d_trans</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L86\" class=\"source_link\">[source]</a></h4>\n\n> <code>conv2d_trans</code>(**`ni`**:`int`, **`nf`**:`int`, **`ks`**:`int`=***`2`***, **`stride`**:`int`=***`2`***, **`padding`**:`int`=***`0`***, **`bias`**=***`False`***) → [`ConvTranspose2d`](https://pytorch.org/docs/stable/nn.html#torch.nn.ConvTranspose2d)\n\nCreate [`nn.ConvTranspose2d`](https://pytorch.org/docs/stable/nn.html#torch.nn.ConvTranspose2d) layer.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "LDhD7WsO0vOA",
        "colab_type": "code",
        "colab": {},
        "outputId": "2d9e2436-3f86-4a99-e5d6-718ac9f4b89f"
      },
      "cell_type": "code",
      "source": [
        "show_doc(conv_layer, doc_string=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"conv_layer\"><code>conv_layer</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L94\" class=\"source_link\">[source]</a></h4>\n\n> <code>conv_layer</code>(**`ni`**:`int`, **`nf`**:`int`, **`ks`**:`int`=***`3`***, **`stride`**:`int`=***`1`***, **`padding`**:`int`=***`None`***, **`bias`**:`bool`=***`None`***, **`is_1d`**:`bool`=***`False`***, **`norm_type`**:`Optional`\\[[`NormType`](/layers.html#NormType)\\]=***`<NormType.Batch: 1>`***, **`use_activ`**:`bool`=***`True`***, **`leaky`**:`float`=***`None`***, **`transpose`**:`bool`=***`False`***, **`init`**:`Callable`=***`'kaiming_normal_'`***, **`self_attention`**:`bool`=***`False`***)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_wPaARI60vOD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The [`conv_layer`](/layers.html#conv_layer) function returns a sequence of [nn.Conv2D](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d), [BatchNorm](https://arxiv.org/abs/1502.03167) and a ReLU or [leaky RELU](https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf) activation function.\n",
        "\n",
        "`n_in` represents the number of size of the input `n_out` the size of the output, `ks` kernel size, `stride` the stride with which we want to apply the convolutions. `bias` will decide if they have bias or not (if None, defaults to True unless using batchnorm). `norm_type` selects type of normalization (or `None`). If `leaky` is None, the activation is a standard `ReLU`, otherwise it's a `LeakyReLU` of slope `leaky`. Finally if `transpose=True`, the convolution is replaced by a `ConvTranspose2D`."
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "8KAE1Xrd0vOE",
        "colab_type": "code",
        "colab": {},
        "outputId": "f65235d2-e099-4c8c-a486-dc9acbebcfb8"
      },
      "cell_type": "code",
      "source": [
        "show_doc(embedding, doc_string=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"embedding\"><code>embedding</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L273\" class=\"source_link\">[source]</a></h4>\n\n> <code>embedding</code>(**`ni`**:`int`, **`nf`**:`int`) → [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "-8xoTM0Z0vOG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create an [embedding layer](https://arxiv.org/abs/1711.09160) with input size `ni` and output size `nf`."
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "rztztcow0vOI",
        "colab_type": "code",
        "colab": {},
        "outputId": "d4b1b24d-a425-4bb6-b68e-4de0fde118cd"
      },
      "cell_type": "code",
      "source": [
        "show_doc(relu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"relu\"><code>relu</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L90\" class=\"source_link\">[source]</a></h4>\n\n> <code>relu</code>(**`inplace`**:`bool`=***`False`***, **`leaky`**:`float`=***`None`***)\n\nReturn a relu activation, maybe `leaky` and `inplace`.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "e9Hx2bBx0vOK",
        "colab_type": "code",
        "colab": {},
        "outputId": "57261de2-b1fd-4a2b-f222-ce68f6b1c7b5"
      },
      "cell_type": "code",
      "source": [
        "show_doc(res_block)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"res_block\"><code>res_block</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L140\" class=\"source_link\">[source]</a></h4>\n\n> <code>res_block</code>(**`nf`**, **`dense`**:`bool`=***`False`***, **`norm_type`**:`Optional`\\[[`NormType`](/layers.html#NormType)\\]=***`<NormType.Batch: 1>`***, **`bottle`**:`bool`=***`False`***, **\\*\\*`conv_kwargs`**)\n\nResnet block of `nf` features. `conv_kwargs` are passed to [`conv_layer`](/layers.html#conv_layer).  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "eUgR-F4t0vON",
        "colab_type": "code",
        "colab": {},
        "outputId": "55970848-519a-4645-8a59-2bd5b2b008ab"
      },
      "cell_type": "code",
      "source": [
        "show_doc(sigmoid_range)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"sigmoid_range\"><code>sigmoid_range</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L149\" class=\"source_link\">[source]</a></h4>\n\n> <code>sigmoid_range</code>(**`x`**, **`low`**, **`high`**)\n\nSigmoid function with range `(low, high)`  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "QOHXeKWs0vOQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "0f2db09f-d2ea-49a4-fc58-f114be646bc3"
      },
      "cell_type": "code",
      "source": [
        "show_doc(simple_cnn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"simple_cnn\"><code>simple_cnn</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L257\" class=\"source_link\">[source]</a></h4>\n\n> <code>simple_cnn</code>(**`actns`**:`Collection`\\[`int`\\], **`kernel_szs`**:`Collection`\\[`int`\\]=***`None`***, **`strides`**:`Collection`\\[`int`\\]=***`None`***, **`bn`**=***`False`***) → [`Sequential`](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential)\n\nCNN with [`conv_layer`](/layers.html#conv_layer) defined by `actns`, `kernel_szs` and `strides`, plus batchnorm if `bn`.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "YnA2kwaW0vOR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Initialization of modules"
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "ql4L11IR0vOS",
        "colab_type": "code",
        "colab": {},
        "outputId": "0f6fcdea-bce3-487d-cd9d-f60cef616a73"
      },
      "cell_type": "code",
      "source": [
        "show_doc(batchnorm_2d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"batchnorm_2d\"><code>batchnorm_2d</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L40\" class=\"source_link\">[source]</a></h4>\n\n> <code>batchnorm_2d</code>(**`nf`**:`int`, **`norm_type`**:[`NormType`](/layers.html#NormType)=***`<NormType.Batch: 1>`***)\n\nA batchnorm2d layer with `nf` features initialized depending on `norm_type`.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "zqer2RLR0vOT",
        "colab_type": "code",
        "colab": {},
        "outputId": "98a206fe-00a0-45e6-ef99-ea31f727959a"
      },
      "cell_type": "code",
      "source": [
        "show_doc(icnr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"icnr\"><code>icnr</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L186\" class=\"source_link\">[source]</a></h4>\n\n> <code>icnr</code>(**`x`**, **`scale`**=***`2`***, **`init`**=***`'kaiming_normal_'`***)\n\nICNR init of `x`, with `scale` and `init` function.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "C_GoVtJA0vOW",
        "colab_type": "code",
        "colab": {},
        "outputId": "777ba43c-03dd-46d2-85c0-d93ccd9126b9"
      },
      "cell_type": "code",
      "source": [
        "show_doc(trunc_normal_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"trunc_normal_\"><code>trunc_normal_</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L268\" class=\"source_link\">[source]</a></h4>\n\n> <code>trunc_normal_</code>(**`x`**:`Tensor`, **`mean`**:`float`=***`0.0`***, **`std`**:`float`=***`1.0`***) → `Tensor`\n\nTruncated normal initialization.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "8U4bDbyj0vOX",
        "colab_type": "code",
        "colab": {},
        "outputId": "a19efbd8-b1a1-4edf-c14e-8f82585fd576"
      },
      "cell_type": "code",
      "source": [
        "show_doc(icnr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"icnr\"><code>icnr</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L186\" class=\"source_link\">[source]</a></h4>\n\n> <code>icnr</code>(**`x`**, **`scale`**=***`2`***, **`init`**=***`'kaiming_normal_'`***)\n\nICNR init of `x`, with `scale` and `init` function.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "hide_input": true,
        "id": "qZLnaHRp0vOa",
        "colab_type": "code",
        "colab": {},
        "outputId": "eb33138a-3272-48f1-e433-f4d7a9ff9cc3"
      },
      "cell_type": "code",
      "source": [
        "show_doc(NormType)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h2 id=\"NormType\">`NormType`</h2>\n\n> <code>Enum</code> = [Batch, BatchZero, Weight, Spectral]\n\nAn enumeration.  ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "pM_tNB210vOc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Undocumented Methods - Methods moved below this line will intentionally be hidden"
      ]
    },
    {
      "metadata": {
        "id": "Q_rqvH_n0vOc",
        "colab_type": "code",
        "colab": {},
        "outputId": "abe73b13-8094-4a8c-8a73-c5770fd87fac"
      },
      "cell_type": "code",
      "source": [
        "show_doc(Debugger.forward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"Debugger.forward\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L182\" class=\"source_link\">[source]</a></h4>\n\n> <code>forward</code>(**`x`**:`Tensor`) → `Tensor`\n\nDefines the computation performed at every call. Should be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them. ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "nG_tZBLX0vOf",
        "colab_type": "code",
        "colab": {},
        "outputId": "04230810-7c66-46fe-ef39-b7f1c4eb8994"
      },
      "cell_type": "code",
      "source": [
        "show_doc(Lambda.forward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"Lambda.forward\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L17\" class=\"source_link\">[source]</a></h4>\n\n> <code>forward</code>(**`x`**)\n\nDefines the computation performed at every call. Should be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them. ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bah4-RfP0vOi",
        "colab_type": "code",
        "colab": {},
        "outputId": "3c4b5c69-94a6-4e85-a29b-bc350ed3f1e5"
      },
      "cell_type": "code",
      "source": [
        "show_doc(AdaptiveConcatPool2d.forward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"AdaptiveConcatPool2d.forward\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L178\" class=\"source_link\">[source]</a></h4>\n\n> <code>forward</code>(**`x`**)\n\nDefines the computation performed at every call. Should be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them. ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "wr4oVvcE0vOk",
        "colab_type": "code",
        "colab": {},
        "outputId": "9e60c582-e6d1-4952-f178-f75f58f8d1cb"
      },
      "cell_type": "code",
      "source": [
        "show_doc(NoopLoss.forward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"NoopLoss.forward\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L251\" class=\"source_link\">[source]</a></h4>\n\n> <code>forward</code>(**`output`**, **\\*`args`**)\n\nDefines the computation performed at every call. Should be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them. ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xx5PcbUJ0vOl",
        "colab_type": "code",
        "colab": {},
        "outputId": "31d5fd88-88f8-471f-b45e-9d7cd7c566f6"
      },
      "cell_type": "code",
      "source": [
        "show_doc(PixelShuffle_ICNR.forward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"PixelShuffle_ICNR.forward\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L211\" class=\"source_link\">[source]</a></h4>\n\n> <code>forward</code>(**`x`**)\n\nDefines the computation performed at every call. Should be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them. ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "8SwLdW4s0vOo",
        "colab_type": "code",
        "colab": {},
        "outputId": "ca45bf54-37f1-4bdf-b643-1c8a80b5be42"
      },
      "cell_type": "code",
      "source": [
        "show_doc(WassersteinLoss.forward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"WassersteinLoss.forward\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L255\" class=\"source_link\">[source]</a></h4>\n\n> <code>forward</code>(**`real`**, **`fake`**)\n\nDefines the computation performed at every call. Should be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them. ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "BIHrTSb40vOq",
        "colab_type": "code",
        "colab": {},
        "outputId": "c5f5a125-fa40-4395-fc47-de9a07e98d3a"
      },
      "cell_type": "code",
      "source": [
        "show_doc(MergeLayer.forward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"MergeLayer.forward\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L138\" class=\"source_link\">[source]</a></h4>\n\n> <code>forward</code>(**`x`**)\n\nDefines the computation performed at every call. Should be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them. ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "YR9OD7mw0vOr",
        "colab_type": "code",
        "colab": {},
        "outputId": "521acd6b-e5e4-4c13-a307-92e52647ada4"
      },
      "cell_type": "code",
      "source": [
        "show_doc(SigmoidRange.forward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"SigmoidRange.forward\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L159\" class=\"source_link\">[source]</a></h4>\n\n> <code>forward</code>(**`x`**)\n\nDefines the computation performed at every call. Should be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them. ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "OE5hhUXE0vOu",
        "colab_type": "code",
        "colab": {},
        "outputId": "234379d0-e338-4866-cbc3-048751890dc2"
      },
      "cell_type": "code",
      "source": [
        "show_doc(MergeLayer.forward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"MergeLayer.forward\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L138\" class=\"source_link\">[source]</a></h4>\n\n> <code>forward</code>(**`x`**)\n\nDefines the computation performed at every call. Should be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them. ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Kp_3Ql1p0vOv",
        "colab_type": "code",
        "colab": {},
        "outputId": "abcc8b8c-0a5b-48ea-8bbf-f465691a9c20"
      },
      "cell_type": "code",
      "source": [
        "show_doc(SelfAttention.forward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"SelfAttention.forward\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L72\" class=\"source_link\">[source]</a></h4>\n\n> <code>forward</code>(**`x`**)\n\nDefines the computation performed at every call. Should be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them. ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "eKHj91ub0vOz",
        "colab_type": "code",
        "colab": {},
        "outputId": "960a41cf-0693-4f57-f3af-a51039021152"
      },
      "cell_type": "code",
      "source": [
        "show_doc(SequentialEx.forward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"SequentialEx.forward\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L117\" class=\"source_link\">[source]</a></h4>\n\n> <code>forward</code>(**`x`**)\n\nDefines the computation performed at every call. Should be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them. ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "nUMlV0xb0vO1",
        "colab_type": "code",
        "colab": {},
        "outputId": "0156e1d8-3982-4a79-dda4-555870fde49e"
      },
      "cell_type": "code",
      "source": [
        "show_doc(SequentialEx.append)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"SequentialEx.append\"><code>append</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L128\" class=\"source_link\">[source]</a></h4>\n\n> <code>append</code>(**`l`**)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "asvi_YNN0vO4",
        "colab_type": "code",
        "colab": {},
        "outputId": "81d3839e-7281-4902-9026-24d7e28cb85e"
      },
      "cell_type": "code",
      "source": [
        "show_doc(SequentialEx.extend)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"SequentialEx.extend\"><code>extend</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L129\" class=\"source_link\">[source]</a></h4>\n\n> <code>extend</code>(**`l`**)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "f1LzD7wB0vO5",
        "colab_type": "code",
        "colab": {},
        "outputId": "ad8fc6f3-aee4-4ba4-df89-821bdbf92767"
      },
      "cell_type": "code",
      "source": [
        "show_doc(SequentialEx.insert)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"SequentialEx.insert\"><code>insert</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L130\" class=\"source_link\">[source]</a></h4>\n\n> <code>insert</code>(**`i`**, **`l`**)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "8DEmSQ_10vO8",
        "colab_type": "code",
        "colab": {},
        "outputId": "bc3362be-a082-4dcb-a2ee-4f6c60d8c9f0"
      },
      "cell_type": "code",
      "source": [
        "show_doc(PartialLayer.forward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"PartialLayer.forward\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L168\" class=\"source_link\">[source]</a></h4>\n\n> <code>forward</code>(**`x`**)\n\nDefines the computation performed at every call. Should be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them. ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "OLQlFz2J0vO-",
        "colab_type": "code",
        "colab": {},
        "outputId": "39ca63f4-62d4-4d69-a944-9fb81c4b8a75"
      },
      "cell_type": "code",
      "source": [
        "show_doc(BatchNorm1dFlat.forward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"BatchNorm1dFlat.forward\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L282\" class=\"source_link\">[source]</a></h4>\n\n> <code>forward</code>(**`x`**)\n\nDefines the computation performed at every call. Should be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them. ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZTjTc-3y0vO_",
        "colab_type": "code",
        "colab": {},
        "outputId": "4cd90945-b161-48fb-98d5-b07f2ed2eeeb"
      },
      "cell_type": "code",
      "source": [
        "show_doc(Flatten.forward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<h4 id=\"Flatten.forward\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L29\" class=\"source_link\">[source]</a></h4>\n\n> <code>forward</code>(**`x`**)\n\nDefines the computation performed at every call. Should be overridden by all subclasses.\n\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them. ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Y0esLd6H0vPD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## New Methods - Please document or move to the undocumented section"
      ]
    }
  ]
}